{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import mplleaflet\n",
    "\n",
    "# The Data is part of the Kaggle Competition: https://www.kaggle.com/c/sf-crime/data\n",
    "df_base = pd.read_csv(\"data/sf-crime/train.csv\")\n",
    "\n",
    "print(df_base.describe())\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #2 Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the value counts of the categories\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x = df_base['Category'], orient='v', order = df_base['Category'].value_counts().index)\n",
    "plt.xticks(rotation=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Crime Counts per Weekday\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.countplot(y = df_base['DayOfWeek'], orient='h', order = df_base['DayOfWeek'].value_counts().index)\n",
    "plt.xticks(rotation=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time to minutes\n",
    "df_base['Hour_Min'] = pd.to_datetime(df_base['Dates']).dt.hour  + pd.to_datetime(df_base['Dates']).dt.minute / 60\n",
    "\n",
    "# Print Crime Counts per Time and Category\n",
    "df_base_filtered = df_base[df_base['Category'].isin([\n",
    "    'PROSTITUTION', \n",
    "    'VEHICLE THEFT', \n",
    "    'DRUG/NARCOTIC', \n",
    "    'WARRENTS', \n",
    "    'BURGLERY', \n",
    "    'FRAUD', \n",
    "    'ASSAULT',\n",
    "    'LARCENY/THEFT',\n",
    "    'VANDALISM'])]\n",
    "\n",
    "sns.displot(x = 'Hour_Min', hue=\"Category\", data = df_base_filtered, kind=\"kde\", height=8, aspect=1.5)\n",
    "plt.figure(figsize=(16,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore what information we can extract from the streetnames\n",
    "for i in df_base['Address'][0:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Function for Features\n",
    "def cart2polar(x, y):\n",
    "    dist = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return dist, phi\n",
    "\n",
    "def preprocessFeatures(dfx):\n",
    "    \n",
    "    # Time Feature Engineering\n",
    "    df = pd.get_dummies(dfx[['DayOfWeek' , 'PdDistrict']])\n",
    "    df['Hour_Min'] = pd.to_datetime(dfx['Dates']).dt.hour + pd.to_datetime(dfx['Dates']).dt.minute / 60\n",
    "    # We add a feature that contains the expontential time\n",
    "    df['Hour_Min_Exp'] = np.exp(df['Hour_Min'])\n",
    "    \n",
    "    df['Day'] = pd.to_datetime(dfx['Dates']).dt.day\n",
    "    df['Month'] = pd.to_datetime(dfx['Dates']).dt.month\n",
    "    df['Year'] = pd.to_datetime(dfx['Dates']).dt.year\n",
    "\n",
    "    month_one_hot_encoded = pd.get_dummies(pd.to_datetime(dfx['Dates']).dt.month, prefix='Month')\n",
    "    df = pd.concat([df, month_one_hot_encoded], axis=1, join=\"inner\")\n",
    "    \n",
    "    # Convert Carthesian Coordinates to Polar Coordinates\n",
    "    df[['X', 'Y']] = dfx[['X', 'Y']] # we maintain the original coordindates as additional features\n",
    "    df['dist'], df['phi'] = cart2polar(dfx['X'], dfx['Y'])\n",
    "  \n",
    "    # Extracting Street Types\n",
    "    df['Is_ST'] = dfx['Address'].str.contains(\" ST\", case=True)\n",
    "    df['Is_AV'] = dfx['Address'].str.contains(\" AV\", case=True)\n",
    "    df['Is_WY'] = dfx['Address'].str.contains(\" WY\", case=True)\n",
    "    df['Is_TR'] = dfx['Address'].str.contains(\" TR\", case=True)\n",
    "    df['Is_DR'] = dfx['Address'].str.contains(\" DR\", case=True)\n",
    "    df['Is_Block'] = dfx['Address'].str.contains(\" Block\", case=True)\n",
    "    df['Is_crossing'] = dfx['Address'].str.contains(\" / \", case=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Processing Function for Labels\n",
    "def encodeLabels(dfx):\n",
    "    df = pd.DataFrame (columns = [])\n",
    "    factor = pd.factorize(dfx['Category'])\n",
    "    return factor\n",
    "\n",
    "# Remove Outliers by Longitude\n",
    "df_cleaned = df_base[df_base['Y']<70]\n",
    "\n",
    "# Encode Labels as Integer\n",
    "factor = encodeLabels(df_cleaned)\n",
    "y_df = factor[0]\n",
    "labels = list(factor[1])\n",
    "# for val, i in enumerate(labels):\n",
    "#     print(val, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4 Visualize the Data on a Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Criminal Activities by Lat and Long\n",
    "df_filtered = df_cleaned.sample(frac=0.05)  \n",
    "#df_filtered = df_cleaned[df_cleaned['Category'].isin(['PROSTITUTION', 'VEHICLE THEFT', 'FRAUD'])].sample(frac=0.05) # to filter \n",
    "\n",
    "groups = df_filtered.groupby('Category')\n",
    "\n",
    "fig, ax = plt.subplots(sharex=False, figsize=(20, 12))\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group['X'], group['Y'], marker='.', linestyle='', label=name, alpha=0.1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the data to a fraction and selected categories\n",
    "df_filtered = df_cleaned.sample(frac=0.01) \n",
    "df_filtered = df_cleaned[df_cleaned['Category'].isin(['PROSTITUTION', 'VEHICLE THEFT', 'FRAUD'])].sample(frac=0.05) # to filter \n",
    "\n",
    "# Visualize Criminal Activities on a Geo Map\n",
    "fig, ax = plt.subplots(sharex=False, figsize=(20, 10))\n",
    "for name, group in groups:\n",
    "    ax.plot(group['X'], group['Y'], marker='.', linestyle='', label=name)\n",
    "mplleaflet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #5 Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_df & test_df\n",
    "x_df = preprocessFeatures(df_cleaned).copy()\n",
    "\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, train_size=0.7, random_state=0)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #6 Train a Random Decision Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single random forest classifier to establish a performance baseline - parameters are a best guess \n",
    "clf = RandomForestClassifier(max_depth=50, random_state=0, n_estimators = 100)\n",
    "clf.fit(x_train, y_train.ravel())\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "results_log = classification_report(y_test, y_pred)\n",
    "print(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #7 Train an XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the XGBoost model\n",
    "param = {'booster': 'gbtree', \n",
    "         'tree_method': 'gpu_hist',\n",
    "         'predictor': 'gpu_predictor',\n",
    "         'max_depth': 70, \n",
    "         'eta': 0.15, \n",
    "         'objective': '{multi:softmax}', \n",
    "         'eval_metric': 'rmse', #e.g., rmse, rmsle, auc, mae, mlogloss\n",
    "         'num_round': 100,\n",
    "         'feature_selector ': 'greedy', #cyclic, greedy, shuffle, random, thrifty\n",
    "         'sampling_method': 'gradient_based'\n",
    "        }\n",
    "\n",
    "xgb_clf = XGBClassifier(param)\n",
    "xgb_clf.fit(x_train, y_train.ravel())\n",
    "score = xgb_clf.score(x_test, y_test.ravel())\n",
    "print(score)\n",
    "\n",
    "# Create predictions on the test dataset\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "\n",
    "# Print a classification report\n",
    "results_log = classification_report(y_test, y_pred)\n",
    "print(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #8 Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a multi-Class Confusion Matrix\n",
    "cnf_matrix = confusion_matrix(y_test.reshape(-1), y_pred)\n",
    "df_cm = pd.DataFrame(cnf_matrix, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.tight_layout()\n",
    "sns.set(font_scale=1.4) #for label size\n",
    "sns.heatmap(df_cm, cbar=True, cmap= \"inferno\", annot=False, fmt='.0f' #, annot_kws={\"size\": 13}\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
