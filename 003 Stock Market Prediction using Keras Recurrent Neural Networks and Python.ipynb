{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote data access for pandas\n",
    "import pandas_datareader as webreader\n",
    "# Mathematical functions \n",
    "import math \n",
    "# Fundamental package for scientific computing with Python\n",
    "import numpy as np \n",
    "# Additional functions for analysing and manipulating data\n",
    "import pandas as pd \n",
    "# Date Functions\n",
    "from datetime import date, timedelta\n",
    "# This function adds plotting functions for calender dates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "# Important package for visualization - we use this to plot the market data\n",
    "import matplotlib.pyplot as plt \n",
    "# Formatting dates\n",
    "import matplotlib.dates as mdates\n",
    "# Packages for measuring model performance / errors\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Tools for predictive data analysis. We will use the MinMaxScaler to normalize the price data \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# Deep learning library, used for neural networks\n",
    "from keras.models import Sequential \n",
    "# Deep learning classes for recurrent and regular densely-connected layers\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Setting the timeframe for the data extraction\n",
    "date_today = date.today().strftime(\"%Y-%m-%d\")\n",
    "date_start = '2010-01-01'\n",
    "\n",
    "# Getting S&P500 quotes\n",
    "stockname = 'S&P500'\n",
    "symbol = '^GSPC'\n",
    "df = webreader.DataReader(\n",
    "    symbol, start=date_start, end=date_today, data_source=\"yahoo\"\n",
    ")\n",
    "\n",
    "# Taking a look at the shape of the dataset\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #2 Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "register_matplotlib_converters()\n",
    "years = mdates.YearLocator() \n",
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "ax1.xaxis.set_major_locator(years)\n",
    "x = df.index\n",
    "y = df['Close']\n",
    "ax1.fill_between(x, 0, y, color='#b9e1fa')\n",
    "ax1.legend([stockname], fontsize=12)\n",
    "plt.title(stockname + ' from '+ date_start + ' to ' + date_today, fontsize=16)\n",
    "plt.plot(y, color='#039dfc', label=stockname, linewidth=1.0)\n",
    "plt.ylabel('S&P500 Points', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #3 Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection - Only Close Data\n",
    "data = df.filter(['Close'])\n",
    "data_unscaled = data.values\n",
    "\n",
    "# Get the number of rows to train the model on 80% of the data \n",
    "training_data_length = math.ceil(len(data_unscaled) * 0.8)\n",
    "\n",
    "# Transform features by scaling each feature to a range between 0 and 1\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "np_data = mmscaler.fit_transform(npdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "sequence_length = 50\n",
    "\n",
    "# Prediction Index\n",
    "index_Close = 0\n",
    "\n",
    "# Split the training data into train and train data sets\n",
    "# As a first step, we get the number of rows to train the model on 80% of the data \n",
    "train_data_len = math.ceil(np_data.shape[0] * 0.8)\n",
    "\n",
    "# Create the training and test data\n",
    "train_data = np_data[0:train_data_len, :]\n",
    "test_data = np_data[train_data_len - sequence_length:, :]\n",
    "\n",
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(sequence_length, data):\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(sequence_length, data_len):\n",
    "        x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "        y.append(data[i, index_Close]) #contains the prediction values for validation (3rd column = Close),  for single-step prediction\n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "# Generate training data and test data\n",
    "x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "# Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Validate that the prediction value and the input match up\n",
    "# The last close price of the second input sample should equal the first prediction value\n",
    "print(x_test[1][sequence_length-1][index_Close])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Model with 100 Neurons \n",
    "# inputshape = 100 Timestamps\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1))) \n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted values\n",
    "predictions = model.predict(x_test)\n",
    "predictions = mmscaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #5 Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean absolute error (MAE)\n",
    "mae = mean_absolute_error(predictions, y_test)\n",
    "print('MAE: ' + str(round(mae, 1)))\n",
    "\n",
    "# Calculate the root mean squarred error (RMSE)\n",
    "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
    "print('RMSE: ' + str(round(rmse, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date from which on the date is displayed\n",
    "display_start_date = \"2018-01-01\" \n",
    "\n",
    "# Add the difference between the valid and predicted prices\n",
    "train = data[:training_data_length + 1]\n",
    "valid = data[training_data_length:]\n",
    "valid.insert(1, \"Predictions\", predictions, True)\n",
    "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"Close\"], True)\n",
    "\n",
    "# Zoom in to a closer timeframe\n",
    "valid = valid[valid.index > display_start_date]\n",
    "train = train[train.index > display_start_date]\n",
    "\n",
    "# Visualize the data\n",
    "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
    "xt = train.index; yt = train[[\"Close\"]]\n",
    "xv = valid.index; yv = valid[[\"Close\", \"Predictions\"]]\n",
    "plt.title(\"Predictions vs Ground Truth\", fontsize=20)\n",
    "plt.ylabel(stockname, fontsize=18)\n",
    "plt.plot(yt, color=\"#039dfc\", linewidth=2.0)\n",
    "plt.plot(yv[\"Predictions\"], color=\"#E91D9E\", linewidth=2.0)\n",
    "plt.plot(yv[\"Close\"], color=\"black\", linewidth=2.0)\n",
    "plt.legend([\"Train\", \"Test Predictions\", \"Ground Truth\"], loc=\"upper left\")\n",
    "\n",
    "# Fill between plotlines\n",
    "ax1.fill_between(xt, 0, yt[\"Close\"], color=\"#b9e1fa\")\n",
    "ax1.fill_between(xv, 0, yv[\"Predictions\"], color=\"#F0845C\")\n",
    "ax1.fill_between(xv, yv[\"Close\"], yv[\"Predictions\"], color=\"grey\") \n",
    "\n",
    "# Create the bar plot with the differences\n",
    "x = valid.index\n",
    "y = valid[\"Difference\"]\n",
    "plt.bar(x, y, width=5, color=\"black\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the valid and predicted prices\n",
    "dif = valid['Close'] - valid['Predictions']\n",
    "valid.insert(2, 'Difference', dif, True)\n",
    "valid.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #6 Predict Next Day's Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fresh data until today and create a new dataframe with only the price data\n",
    "price_quote = webreader.DataReader(symbol, data_source='yahoo', start=date_start, end=date_today)\n",
    "new_df = price_quote.filter(['Close'])\n",
    "\n",
    "# Get the last 100 day closing price values and scale the data to be values between 0 and 1\n",
    "last_100_days = new_df[-100:].values\n",
    "last_100_days_scaled = mmscaler.transform(new_df[-100:].values)\n",
    "\n",
    "# Create an empty list and Append past 100 days\n",
    "X_test = []\n",
    "X_test.append(last_100_days_scaled)\n",
    "\n",
    "# Convert the X_test data set to a numpy array and reshape the data\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Get the predicted scaled price, undo the scaling and output the predictions\n",
    "pred_price = model.predict(X_test)\n",
    "pred_price_unscaled = mmscaler.inverse_transform(pred_price)\n",
    "\n",
    "# Print last price and predicted price for the next day\n",
    "price_today = round(new_df['Close'][-1], 2)\n",
    "predicted_price = round(pred_price_unscaled.ravel()[0], 2)\n",
    "percent = round(100 - (predicted_price * 100)/price_today, 2)\n",
    "\n",
    "plus = '+'; minus = '-'\n",
    "print(f'The close price for {stockname} at {today} was {price_today}')\n",
    "print(f'The predicted close price is {predicted_price} ({plus if percent > 0 else minus}{percent}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
